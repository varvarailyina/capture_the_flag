{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDC: Developing Bots & Scrapers with Python\n",
    "#### Capture the Flag\n",
    "<br>\n",
    "Varvara Ilyina\n",
    "\n",
    "2024-04-07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following code, I am able to scrape flags 1-7 from the center of the page, the flags 7-39, which are hidden behind the flag images at the bottom of the first page, as well as the other flags behind the images at the bottom of the first page.\n",
    "\n",
    "These are appended to a shared list. The formatting is incorrect and the list is not ordered.\n",
    "\n",
    "I did not get to scraping the other three pages or using selenium yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flag-1', 'flag-2', 'flag-3', 'flag-4', 'flag-5', 'flag-6', 'flag-7', 'flag-7', 'flag-8', 'flag-9', 'flag-11', 'flag-13', 'flag-15', 'flag-17', 'flag-19', 'flag-21', 'flag-23', 'flag-25', 'flag-27', 'flag-29', 'flag-31', 'flag-33', 'flag-35', 'flag-37', 'flag-39', ['flag-10'], ['flag-12'], ['flag-14'], ['flag-16'], ['flag-18'], ['flag-20'], ['flag-22'], ['flag-24'], ['flag-26'], ['flag-28'], ['flag-30'], ['flag-32'], ['flag-34'], ['flag-36'], ['flag-38'], ['flag-40']]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# define url\n",
    "URL = \"https://hertie-scraping-website.vercel.app/\"\n",
    "\n",
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "# print soup\n",
    "#print(soup.prettify())\n",
    "\n",
    "# create empty list to append flag texts and flag ids\n",
    "flags_list = []\n",
    "\n",
    "# find flags in p tags\n",
    "all_p_tags = soup.find_all('p', class_='text-base')\n",
    "\n",
    "for p_tag in all_p_tags[2:]:\n",
    "    flag_text = p_tag.text\n",
    "    flags_list.append(flag_text)\n",
    "\n",
    "# find all elements with an id attribute with \"flag\" in it\n",
    "flag_elements = soup.select('[id*=flag]')\n",
    "\n",
    "# loop through found elements and append their id attributes to the flags_list\n",
    "for element in flag_elements:\n",
    "    flag_id = element.get('id')\n",
    "    flags_list.append(flag_id)\n",
    "\n",
    "# find all elements with a class attribute with \"flag\" in it\n",
    "more_flags = soup.select('[class*=flag]')\n",
    "\n",
    "# loop through found elements and append their class attributes to the flags_list\n",
    "for element in more_flags:\n",
    "    flag_class = element.get('class')\n",
    "    flags_list.append(flag_class)\n",
    "\n",
    "print(flags_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "<hr>\n",
    "<br>\n",
    "The code below just extracts the flags 1-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag-1\n",
      "flag-2\n",
      "flag-3\n",
      "flag-4\n",
      "flag-5\n",
      "flag-6\n",
      "flag-7\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://hertie-scraping-website.vercel.app/\"\n",
    "\n",
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "# create empty list to append\n",
    "flags_list = []\n",
    "\n",
    "# find first flag\n",
    "all_flags = soup.find('div', id='nesting-1')\n",
    "#print(all_flags)\n",
    "\n",
    "# find flags in p tags\n",
    "all_p_tags = soup.find_all('p', class_='text-base')\n",
    "#print(all_p_tags)\n",
    "\n",
    "for p_tag in all_p_tags[2:]:\n",
    "    print(p_tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "The code below just extracts the flags 7-39 from the images at the bottom of the first page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag-7\n",
      "flag-8\n",
      "flag-9\n",
      "flag-11\n",
      "flag-13\n",
      "flag-15\n",
      "flag-17\n",
      "flag-19\n",
      "flag-21\n",
      "flag-23\n",
      "flag-25\n",
      "flag-27\n",
      "flag-29\n",
      "flag-31\n",
      "flag-33\n",
      "flag-35\n",
      "flag-37\n",
      "flag-39\n"
     ]
    }
   ],
   "source": [
    "# find all elements that contain an id attribute with \"flag\" in it\n",
    "flag_elements = soup.select('[id*=flag]')\n",
    "\n",
    "# print the found elements\n",
    "#for element in flag_elements:\n",
    "#    print(element)\n",
    "\n",
    "for element in flag_elements:\n",
    "    # Extract the id attribute value\n",
    "    flag_id = element.get('id')\n",
    "    print(flag_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "The code below just extracts the missing flags from the images at the bottom of the first page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flag-10']\n",
      "['flag-12']\n",
      "['flag-14']\n",
      "['flag-16']\n",
      "['flag-18']\n",
      "['flag-20']\n",
      "['flag-22']\n",
      "['flag-24']\n",
      "['flag-26']\n",
      "['flag-28']\n",
      "['flag-30']\n",
      "['flag-32']\n",
      "['flag-34']\n",
      "['flag-36']\n",
      "['flag-38']\n",
      "['flag-40']\n",
      "[['flag-10'], ['flag-12'], ['flag-14'], ['flag-16'], ['flag-18'], ['flag-20'], ['flag-22'], ['flag-24'], ['flag-26'], ['flag-28'], ['flag-30'], ['flag-32'], ['flag-34'], ['flag-36'], ['flag-38'], ['flag-40'], ['flag-10'], ['flag-12'], ['flag-14'], ['flag-16'], ['flag-18'], ['flag-20'], ['flag-22'], ['flag-24'], ['flag-26'], ['flag-28'], ['flag-30'], ['flag-32'], ['flag-34'], ['flag-36'], ['flag-38'], ['flag-40']]\n"
     ]
    }
   ],
   "source": [
    "# find all elements that contain a class attribute with \"flag\" in it\n",
    "more_flags = soup.select('[class*=flag]')\n",
    "\n",
    "# loop through found elements and append their class attributes to the flags_list\n",
    "for element in more_flags:\n",
    "    flag_class = element.get('class')\n",
    "    flags_list.append(flag_class)\n",
    "    \n",
    "    print(flag_class)\n",
    "\n",
    "\n",
    "# loop through found elements and append their class attributes to the flags_list\n",
    "for element in more_flags:\n",
    "    flag_class = element.get('class')\n",
    "    flags_list.append(flag_class)\n",
    "\n",
    "print(flags_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
